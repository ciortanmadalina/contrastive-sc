{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import st_loss\n",
    "\n",
    "import h5py\n",
    "import scipy as sp\n",
    "import scanpy.api as sc\n",
    "from collections import Counter\n",
    "import utils\n",
    "import loop\n",
    "import pickle\n",
    "import os\n",
    "import glob2\n",
    "plt.ion()\n",
    "plt.show()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"balanced_data\"\n",
    "path = \"../\"\n",
    "args = {\n",
    "    \"dims\": [499, 256, 64, 32],\n",
    "    \"highly_genes\": 500,\n",
    "    'alpha': 0.001,\n",
    "    'gamma': 0.001,\n",
    "    'learning_rate': 0.0001,\n",
    "    'update_epoch': 10,\n",
    "    't_alpha': 1,\n",
    "    'error': 0.001\n",
    "}\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "args = objectview(args)\n",
    "\n",
    "files = glob2.glob(f'../R/simulated_data/{category}/*.h5')\n",
    "files = [f[len(f\"{path}R/simulated_data/{category}/\"):-3] for f in files]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dr = pd.DataFrame(\n",
    "    columns=[\"dataset\", \"dropout\", \"perc0\", \"nb_genes\", \"exp\", \"ari\"])\n",
    "for run in range(1):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    print(df.shape)\n",
    "    for dataset in files:\n",
    "        print(f\">>>>> Data {dataset}\")\n",
    "\n",
    "        data_mat = h5py.File(f\"{path}R/simulated_data/{category}/{dataset}.h5\", \"r\")\n",
    "        for nb_genes in [100, 200, 500, 1000, 1500]:\n",
    "            dp = data_mat['dropout'][0]\n",
    "            X = np.array(data_mat['X'])\n",
    "            Y = np.array(data_mat['Y'])\n",
    "            perc_0 = np.where(X == 0)[0].shape[0] / (X.shape[0] * X.shape[1])\n",
    "            print(f\"Perc 0 {perc_0}\")\n",
    "            X = np.ceil(X).astype(np.int)\n",
    "            count_X = X\n",
    "            print(X.shape, count_X.shape)\n",
    "            orig_X = X.copy()\n",
    "            adata = sc.AnnData(X)\n",
    "            adata.obs['Group'] = Y\n",
    "            adata = utils.normalize(adata,\n",
    "                                    copy=True,\n",
    "                                    highly_genes=nb_genes,\n",
    "                                    size_factors=True,\n",
    "                                    normalize_input=True,\n",
    "                                    logtrans_input=True)\n",
    "            X = adata.X.astype(np.float32)\n",
    "            Y = np.array(adata.obs[\"Group\"])\n",
    "            print(X.shape, count_X.shape)\n",
    "\n",
    "            high_variable = np.array(adata.var.highly_variable.index,\n",
    "                                     dtype=np.int)\n",
    "            count_X = count_X[:, high_variable]\n",
    "            # X=X[:, high_variable]\n",
    "            size_factor = np.array(adata.obs.size_factors).reshape(\n",
    "                -1, 1).astype(np.float32)\n",
    "            cluster_number = int(max(Y) - min(Y) + 1)\n",
    "            zeros = np.min(X, axis=0)\n",
    "            X.shape, count_X.shape\n",
    "\n",
    "            pxt = PCA(2).fit_transform(X)\n",
    "            dresults = {\n",
    "                \"dataset\": dataset,\n",
    "                \"nclust\": cluster_number,\n",
    "                \"original\": utils.evaluate(X, Y, cluster_number)[1],\n",
    "                \"pca\": utils.evaluate(pxt, Y, cluster_number)[1],\n",
    "                \"perc_0\": perc_0\n",
    "            }\n",
    "\n",
    "            # 3 models\n",
    "            st_results = []\n",
    "\n",
    "            f = []\n",
    "            nb_zeros = int(0.8 * nb_genes)\n",
    "            print(f\"nb_zeros = {nb_zeros}, nb_genes= {nb_genes}\")\n",
    "            nm = nb_genes\n",
    "            r1 = loop.self_train_clustering(X,\n",
    "                                            Y,\n",
    "                                            cluster_number,\n",
    "                                            args,\n",
    "                                            augm_zeros=None,\n",
    "                                            nb_zeros=nb_zeros,\n",
    "                                            random=False,\n",
    "                                            perc=0.1,\n",
    "                                            augm_value=0,\n",
    "                                            model_name=\"STClustering\",\n",
    "                                            epochs=500)\n",
    "            f.append(r1['features'])\n",
    "            st_results.append(r1)\n",
    "\n",
    "            dresults[f\"self_initial_{nm}\"] = r1[\"aris_kmeans_representation\"][\n",
    "                -1]\n",
    "            dresults[f\"self_{nm}\"] = r1[\"aris\"][-1]\n",
    "            dr.loc[dr.shape[0]] = [\n",
    "                dataset, dp, perc_0, nb_genes, \"method1-kmeans\",\n",
    "                r1[\"aris_kmeans_representation\"][-1]\n",
    "            ]\n",
    "            dr.loc[dr.shape[0]] = [\n",
    "                dataset, dp, perc_0, nb_genes, \"method1-leiden\",\n",
    "                r1[\"ari_leiden_representation\"]\n",
    "            ]\n",
    "            \n",
    "            \n",
    "            dr.loc[dr.shape[0]] = [\n",
    "                dataset, dp, perc_0, nb_genes, \"method2\", r1[\"aris\"][-1]\n",
    "            ]\n",
    "            print(\"ARI \", r1[\"aris_kmeans_representation\"][-1], \" leiden \",\n",
    "                 r1[\"ari_leiden_representation\"])\n",
    "            df = df.append(dresults, ignore_index=True)\n",
    "            print(dresults)\n",
    "            all_res = dresults.copy()\n",
    "            all_res[\"st\"] = st_results\n",
    "            if os.path.isdir(f\"{path}output/{category}/\") == False:\n",
    "                os.makedirs(f\"{path}output/{category}/\",exist_ok=True)\n",
    "            with open(\n",
    "                    f\"{path}output/{category}/results_{dataset}_{run}_input_size.pickle\",\n",
    "                    'wb') as handle:\n",
    "                pickle.dump(dresults, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "            with open(\n",
    "                    f\"{path}output/{category}/detailed_results_{dataset}_{run}_input_size.pickle\",\n",
    "                    'wb') as handle:\n",
    "                pickle.dump(all_res, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            df.to_pickle(f\"{path}output/pickle_results/{category}/real_data_{run}_input_size.pkl\")\n",
    "            dr.to_pickle(f\"{path}output/pickle_results/{category}/real_data_input_size.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.read_pickle(f\"{path}output/pickle_results/{category}/real_data_input_size.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = dr.rename(columns = {\"nb_genes\": \"Nb input genes\"})\n",
    "\n",
    "exp_names = {\n",
    "    'method1-kmeans': \"Baseline + KMeans\", \n",
    "    'method1-leiden': \"Baseline + Leiden\", \n",
    "    'method2': \"Cluster network\"\n",
    "}\n",
    "\n",
    "dr[\"exp\"] = dr[\"exp\"].apply(lambda x: exp_names[x] if x in exp_names else x  )\n",
    "\n",
    "# dr.to_pickle(f\"{path}output/pickle_results/{category}/real_data_input_size.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "ax = plt.subplot(111)\n",
    "sns.barplot(\n",
    "    hue=\"Nb input genes\",\n",
    "    y=\"ari\",\n",
    "    x=\"exp\",\n",
    "    data=dr,\n",
    "    ax=ax,\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5,\n",
    ")\n",
    "sns.despine()\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"Method\")\n",
    "plt.savefig(f\"{path}diagrams/balanced_input_size.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
