{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original implementation of Contrastive-sc method\n",
    "(https://github.com/ciortanmadalina/contrastive-sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "from sklearn.metrics import (adjusted_rand_score, normalized_mutual_info_score, \n",
    "                             silhouette_score, calinski_harabasz_score,\n",
    "                             davies_bouldin_score)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import st_loss\n",
    "\n",
    "import h5py\n",
    "import scipy as sp\n",
    "import scanpy.api as sc\n",
    "from collections import Counter\n",
    "import random\n",
    "import utils\n",
    "import loop\n",
    "import pickle\n",
    "\n",
    "import train\n",
    "import os\n",
    "import glob2\n",
    "plt.ion()\n",
    "plt.show()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../\"\n",
    "category = \"balanced_data\"\n",
    "# category = \"imbalanced_data\"\n",
    "category = \"real_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_baseline.pkl\")\n",
    "df.groupby([\"temperature\", \"layers\", \"dropout\", \"lr\"])[\"kmeans_ari_0\"].mean().unstack([\"layers\", \"lr\"])\n",
    "\n",
    "df_k = df[[\n",
    "    'dataset',\n",
    "    'dropout',\n",
    "    'kmeans_ari_0',\n",
    "    'kmeans_nmi_0',\n",
    "    'run',\n",
    "    \"time\",\n",
    "    'kmeans_pred_0',\n",
    "]].rename(columns={\n",
    "    'kmeans_ari_0': \"ARI\",\n",
    "    'kmeans_nmi_0': \"NMI\",\n",
    "    'kmeans_pred_0': 'pred'\n",
    "})\n",
    "df_k[\"method\"] = \"Ours+KM\"\n",
    "\n",
    "df_l = df[[\n",
    "    'dataset',\n",
    "    'dropout',\n",
    "    'leiden_ari_0',\n",
    "    'leiden_nmi_0',\n",
    "    'run',\n",
    "    'time',\n",
    "    'leiden_pred_0',\n",
    "]].rename(columns={\n",
    "    'leiden_ari_0': \"ARI\",\n",
    "    'leiden_nmi_0': \"NMI\",\n",
    "    'leiden_pred_0': 'pred'\n",
    "})\n",
    "\n",
    "df_l[\"method\"] = \"Ours+Leiden\"\n",
    "\n",
    "r_data = pd.read_pickle(f\"../R/{category}.pkl\")\n",
    "\n",
    "scDeepCluster = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_scDeepCluster.pkl\")\n",
    "scDeepCluster[\"method\"] = \"scDeepCluster\"\n",
    "\n",
    "sczi = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_sczi.pkl\")\n",
    "sczi[\"method\"] = \"sczi\"\n",
    "\n",
    "scedar = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_scedar.pkl\")\n",
    "scedar[\"method\"] = \"scedar\"\n",
    "\n",
    "scanpy = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_scanpy.pkl\")\n",
    "scanpy[\"method\"] = \"scanpy\"\n",
    "\n",
    "scrna = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_scrna.pkl\")\n",
    "scrna[\"method\"] = \"scrna\"\n",
    "\n",
    "pca_kmeans = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_pca_kmeans.pkl\")\n",
    "pca_kmeans[\"method\"] = \"pca_kmeans\"\n",
    "\n",
    "desc = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_desc.pkl\")\n",
    "desc[\"pred\"] = desc[\"pred\"].apply(lambda x: x.to_list())\n",
    "desc[\"method\"] = \"desc\"\n",
    "\n",
    "all_data = pd.concat([df_k, df_l, r_data, desc,pca_kmeans, sczi, \n",
    "                      scDeepCluster ,scedar, scanpy, scrna])\n",
    "all_data = all_data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>dropout</th>\n",
       "      <th>ARI</th>\n",
       "      <th>NMI</th>\n",
       "      <th>run</th>\n",
       "      <th>time</th>\n",
       "      <th>pred</th>\n",
       "      <th>method</th>\n",
       "      <th>sil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quake_Smart-seq2_Trachea</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.502064</td>\n",
       "      <td>0.580774</td>\n",
       "      <td>0</td>\n",
       "      <td>2.611309</td>\n",
       "      <td>[0, 3, 2, 3, 3, 0, 2, 3, 3, 0, 0, 2, 0, 0, 0, ...</td>\n",
       "      <td>Ours+KM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quake_Smart-seq2_Trachea</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.469278</td>\n",
       "      <td>0.542781</td>\n",
       "      <td>1</td>\n",
       "      <td>0.964024</td>\n",
       "      <td>[0, 2, 1, 2, 2, 0, 1, 2, 2, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>Ours+KM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quake_Smart-seq2_Diaphragm</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.985385</td>\n",
       "      <td>0.972357</td>\n",
       "      <td>0</td>\n",
       "      <td>0.697230</td>\n",
       "      <td>[0, 1, 1, 3, 3, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Ours+KM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quake_Smart-seq2_Diaphragm</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.983543</td>\n",
       "      <td>0.966968</td>\n",
       "      <td>1</td>\n",
       "      <td>0.721800</td>\n",
       "      <td>[0, 2, 2, 4, 4, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Ours+KM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quake_10x_Spleen</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.493249</td>\n",
       "      <td>0.641360</td>\n",
       "      <td>0</td>\n",
       "      <td>6.730129</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 3, 3, 2, 0, 0, 4, 0, 0, ...</td>\n",
       "      <td>Ours+KM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      dataset  dropout       ARI       NMI run      time  \\\n",
       "0    Quake_Smart-seq2_Trachea      0.9  0.502064  0.580774   0  2.611309   \n",
       "1    Quake_Smart-seq2_Trachea      0.9  0.469278  0.542781   1  0.964024   \n",
       "2  Quake_Smart-seq2_Diaphragm      0.9  0.985385  0.972357   0  0.697230   \n",
       "3  Quake_Smart-seq2_Diaphragm      0.9  0.983543  0.966968   1  0.721800   \n",
       "4            Quake_10x_Spleen      0.9  0.493249  0.641360   0  6.730129   \n",
       "\n",
       "                                                pred   method  sil  \n",
       "0  [0, 3, 2, 3, 3, 0, 2, 3, 3, 0, 0, 2, 0, 0, 0, ...  Ours+KM  NaN  \n",
       "1  [0, 2, 1, 2, 2, 0, 1, 2, 2, 0, 0, 1, 0, 0, 0, ...  Ours+KM  NaN  \n",
       "2  [0, 1, 1, 3, 3, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0, ...  Ours+KM  NaN  \n",
       "3  [0, 2, 2, 4, 4, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  Ours+KM  NaN  \n",
       "4  [0, 1, 0, 0, 0, 0, 0, 3, 3, 2, 0, 0, 4, 0, 0, ...  Ours+KM  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Silhouette\"] = np.nan\n",
    "all_data[\"Calinski\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quake_Smart-seq2_Trachea', 'Quake_Smart-seq2_Diaphragm', 'Quake_10x_Spleen', 'Young', 'mouse_ES_cell', 'Adam', 'Quake_10x_Bladder', 'Quake_Smart-seq2_Lung', 'Quake_10x_Limb_Muscle', 'worm_neuron_cell', 'mouse_bladder_cell', 'Romanov', 'Quake_Smart-seq2_Limb_Muscle', 'Muraro', '10X_PBMC']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c3d4a898df4ad4a2fc01374c580de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1350, 23341) (1350, 23341) keeping 500 genes\n",
      "(870, 23341) (870, 23341) keeping 500 genes\n",
      "(9552, 23341) (9552, 23341) keeping 500 genes\n",
      "(5685, 33658) (5685, 33658) keeping 500 genes\n"
     ]
    }
   ],
   "source": [
    "path= \"..\"\n",
    "if category in [\"balanced_data\", \"imbalanced_data\"]:\n",
    "    files = glob2.glob(f'{path}/R/simulated_data/{category}/*.h5')\n",
    "    files = [f[len(f\"{path}/R/simulated_data/{category}/\"):-3] for f in files]\n",
    "else:\n",
    "    files = glob2.glob(f'{path}/real_data/*.h5')\n",
    "    files = [f[len(f\"{path}/real_data/\"):-3] for f in files]\n",
    "print(files)\n",
    "\n",
    "for dataset in tqdm(files):\n",
    "    if category in [\"balanced_data\", \"imbalanced_data\"]:\n",
    "        data_mat = h5py.File(f\"{path}/R/simulated_data/{category}/{dataset}.h5\",\"r\")\n",
    "    else:\n",
    "        data_mat = h5py.File(f\"{path}/real_data/{dataset}.h5\",\"r\")\n",
    "\n",
    "    Y = np.array(data_mat['Y'])\n",
    "    X = np.array(data_mat['X'])\n",
    "    X = train.preprocess(X, nb_genes=500)\n",
    "    X = PCA(n_components=5).fit_transform(X)\n",
    "    \n",
    "    ss = [silhouette_score(X,predi ) for predi in all_data[all_data[\"dataset\"] == dataset][\"pred\"].values ]\n",
    "    all_data.loc[all_data[all_data[\"dataset\"] == dataset].index.values, \"Silhouette\"] = ss\n",
    "#     ss = [davies_bouldin_score(X,predi ) for predi in all_data[all_data[\"dataset\"] == dataset][\"pred\"].values ]\n",
    "#     all_data.loc[all_data[all_data[\"dataset\"] == dataset].index.values, \"Calinski\"] = ss\n",
    "    ss = [calinski_harabasz_score(X,predi ) for predi in all_data[all_data[\"dataset\"] == dataset][\"pred\"].values ]\n",
    "    all_data.loc[all_data[all_data[\"dataset\"] == dataset].index.values, \"Calinski\"] = ss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if category in [\"imbalanced_data\", \"balanced_data\"]:\n",
    "    sc_dropout = {\n",
    "        'data_1c8': 0.3,\n",
    "        'data_-1c4': 0.08,\n",
    "        'data_-1c8': 0.08,\n",
    "        'data_0c4': 0.17,\n",
    "        'data_0c8': 0.17,\n",
    "        'data_0c16': 0.17,\n",
    "        'data_1.5c4': 0.38,\n",
    "        'data_1c4': 0.3,\n",
    "        'data_1.5c8': 0.38,\n",
    "        'data_1.5c16': 0.38,\n",
    "        'data_-1c16': 0.08,\n",
    "        'data_1c16': 0.3,\n",
    "        'data_0c32': 0.17,\n",
    "        'data_1.5c32': 0.38,\n",
    "        'data_1c32': 0.3,\n",
    "        'data_-1c32': 0.08\n",
    "    }\n",
    "    all_data[\"dropout\"] = all_data[\"dataset\"].apply(lambda x: sc_dropout[x])\n",
    "    all_data[\"nb_clust\"]= all_data[\"dataset\"].apply(lambda x: int(x.split(\"c\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_methods = [\n",
    "    'Ours+KM',\n",
    "    'Ours+Leiden',\n",
    "    'sczi',\n",
    "    'scDeepCluster',\n",
    "    'desc',\n",
    "    'scanpy',\n",
    "    'scedar',\n",
    "    'scrna',\n",
    "    'soup',\n",
    "    'simlr',\n",
    "    'raceid',\n",
    "    'cidr',\n",
    "    'pca_kmeans',\n",
    "]\n",
    "ordered_methods = dict(zip(ordered_methods, np.arange(len(ordered_methods))))\n",
    "\n",
    "all_data[\"order\"] = all_data[\"method\"].apply(lambda x: ordered_methods[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_pickle(f\"../output/pickle_results/{category}/{category}_combined.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category = \"imbalanced_data\"\n",
    "# category = \"balanced_data\"\n",
    "# category = \"real_data\"\n",
    "# all_data = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_combined.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = \"method\", y=\"time\", data = all_data.sort_values(by=\"order\"))\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs = ['#C0392B', \"#F1948A\", \"#D7BDE2\", \"#8E44AD\", \"#7FB3D5\", \"#2874A6\", \"#76D7C4\", \"#117A65\",\n",
    "        \"#A9DFBF\", \"#F1C40F\", \"#EB984E\", \"#839192\", \"#566573\"\n",
    "       ]\n",
    "len(clrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Comparaision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "ax = plt.subplot(141)\n",
    "sns.barplot(x = \"method\", y=\"ARI\", data = all_data.sort_values(by=\"order\"),\n",
    "           palette=clrs,\n",
    "           edgecolor='black',\n",
    "    linewidth=1.5)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"(a) ARI\")\n",
    "plt.xlabel(\"\")\n",
    "sns.despine()\n",
    "\n",
    "ax = plt.subplot(142)\n",
    "sns.barplot(x = \"method\", y=\"NMI\", data = all_data.sort_values(by=\"order\"),\n",
    "           palette=clrs,\n",
    "           edgecolor='black',\n",
    "    linewidth=1.5)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.xlabel(\"\")\n",
    "plt.title(\"(b) NMI\")\n",
    "\n",
    "ax = plt.subplot(143)\n",
    "sns.barplot(x = \"method\", y=\"Silhouette\", data = all_data.sort_values(by=\"order\"),\n",
    "           palette=clrs,\n",
    "           edgecolor='black',\n",
    "    linewidth=1.5)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"(c) Silhouette\")\n",
    "plt.xlabel(\"\")\n",
    "sns.despine()\n",
    "\n",
    "ax = plt.subplot(144)\n",
    "sns.barplot(x = \"method\", y=\"Calinski\", data = all_data.sort_values(by=\"order\"),\n",
    "           palette=clrs,\n",
    "           edgecolor='black',\n",
    "    linewidth=1.5)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"(d) Calinski\")\n",
    "plt.xlabel(\"\")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"../diagrams/{category}_barplot.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"(a)\", \"(b)\", \"(c)\", \"(d)\"]\n",
    "plt.figure(figsize = (12, 5))\n",
    "for i, dropout in enumerate(sorted(all_data.dropout.unique())):\n",
    "    ax = plt.subplot(2, 2, i+1)\n",
    "    sns.barplot(x = \"nb_clust\", y=\"ARI\", \n",
    "                data = all_data[all_data[\"dropout\"] == dropout].sort_values(by=[\"nb_clust\", \"order\"]),\n",
    "                hue = \"method\",\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=1.5)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"{titles[i]} dropout rate {dropout} %\")\n",
    "    if i ==1:\n",
    "        plt.legend(bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "    else: \n",
    "        plt.legend([],[], frameon=False)\n",
    "    if i in [2, 3]:\n",
    "        plt.xlabel(\"Nb. of clusters\")\n",
    "    else:\n",
    "        plt.xlabel(\"\")\n",
    "    sns.despine()\n",
    "# plt.tight_layout()\n",
    "plt.savefig(f\"../diagrams/{category}_barplot_by_dropout.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 12))\n",
    "letters = [\"(a)\", \"(b)\", \"(c)\", \"(d)\",\n",
    "           \"(e)\", \"(f)\",\"(g)\" ,\"(h)\",\n",
    "           \"(i)\",\"(j)\",\"(k)\", \"(l)\"]\n",
    "titles = [\"balanced data\", \"imbalanced data\", \"real data\"]\n",
    "for i, category in enumerate ([\"balanced_data\", \"imbalanced_data\", \"real_data\"] ):\n",
    "    all_data = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_combined.pkl\")\n",
    "    \n",
    "    ax = plt.subplot(3,4,i*4 +1)\n",
    "    sns.barplot(x = \"method\", y=\"ARI\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=1.5)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"{letters[i*4]} ARI {titles[i]}\")\n",
    "    plt.xlabel(\"\")\n",
    "    sns.despine()\n",
    "\n",
    "    ax = plt.subplot(3,4,i*4 +2)\n",
    "    sns.barplot(x = \"method\", y=\"NMI\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=1.5)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.title(f\"{letters[i*4 +1]} NMI {titles[i]}\")\n",
    "\n",
    "    ax = plt.subplot(3,4,i*4 +3)\n",
    "    sns.barplot(x = \"method\", y=\"Silhouette\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=1.5)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"{letters[i*4 +2]} Silhouette {titles[i]}\")\n",
    "    plt.xlabel(\"\")\n",
    "    sns.despine()\n",
    "\n",
    "    ax = plt.subplot(3,4,i*4 +4)\n",
    "    sns.barplot(x = \"method\", y=\"Calinski\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=1.5)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"{letters[i*4 +3]}  Calinski {titles[i]}\")\n",
    "    plt.xlabel(\"\")\n",
    "    sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"../diagrams/all_barplot.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"dataset\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    columns=[\"dataset\", \"perc0\", \"nb_genes\", \"exp\", \"ari\", \"run\"])\n",
    "print(df.shape)\n",
    "for dataset in files:\n",
    "\n",
    "    print(f\">>>>> Data {dataset}\")\n",
    "\n",
    "    data_mat = h5py.File(f\"{path}real_data/{dataset}.h5\", \"r\")\n",
    "    for run in range(2):\n",
    "        torch.manual_seed(run)\n",
    "        torch.cuda.manual_seed_all(run)\n",
    "        np.random.seed(run)\n",
    "        random.seed(run)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        for nb_genes in [100, 200, 500, 1000, 1500, 2000, 5000, 8000]:\n",
    "\n",
    "            X = np.array(data_mat['X'])\n",
    "            Y = np.array(data_mat['Y'])\n",
    "            perc_0 = np.where(X == 0)[0].shape[0] / (X.shape[0] * X.shape[1])\n",
    "            print(f\"Perc 0 {perc_0}\")\n",
    "            cluster_number = np.unique(Y).shape[0]\n",
    "\n",
    "            X = train.preprocess(X, nb_genes=nb_genes)\n",
    "            nb_zeros = int(0.8 * nb_genes)\n",
    "            dresults = train.train(\n",
    "                X,\n",
    "                cluster_number,\n",
    "                dataset,\n",
    "                Y,\n",
    "                n_ensemble=1,\n",
    "                epochs=100,\n",
    "                nb_zeros=nb_zeros,\n",
    "                save_to=f\"{path}output/real_data/inputs/{dataset}_{nb_genes}/\")\n",
    "\n",
    "            #         df.loc[df.shape[0]] = [\n",
    "            #                 dataset, perc_0, nb_genes, 'kmeans_representation_0',dresults['kmeans_representation_0']\n",
    "            #             ]\n",
    "            df.loc[df.shape[0]] = [\n",
    "                dataset, perc_0, nb_genes, 'leiden_representation_0',\n",
    "                dresults['leiden_representation_0'], run]\n",
    "\n",
    "#             pxt = PCA(2).fit_transform(X)\n",
    "#             dresults[\"original\"] = utils.evaluate(X, Y, cluster_number)[1]\n",
    "#             dresults[\"pca\"] = utils.evaluate(pxt, Y, cluster_number)[1]\n",
    "            print(dresults)\n",
    "    df.to_pickle(f\"{path}output/pickle_results/real_data_input_size.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{path}output/pickle_results/real_data_input_size.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"nb_genes\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = {\n",
    "    '10X_PBMC': '10X PBMC',\n",
    "    '10X_PBMC_select_2100': '10X PBMC (2100)',\n",
    "    'mouse_ES_cell': 'Mouse ES\\nCell',\n",
    "    'mouse_ES_cell_select_2100': 'Mouse ES\\nCell (2100)',\n",
    "    'worm_neuron_cell_select_2100': 'Worm Neuron\\nCell (2100)',\n",
    "    'worm_neuron_cell': 'Worm Neuron\\nCell',\n",
    "    'mouse_bladder_cell': 'Mouse Bladder\\nCell',\n",
    "    'mouse_bladder_cell_select_2100': 'Mouse Bladder\\n Cell (2100)'\n",
    "}\n",
    "\n",
    "df[\"dataset\"] = df[\"dataset\"].apply(lambda x: dataset_names[x])\n",
    "\n",
    "df = df.rename(columns = {\"nb_genes\": \"Nb input genes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dataset\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "datasets = ['10X PBMC',  'Mouse ES\\nCell','Worm Neuron\\nCell', 'Mouse Bladder\\nCell']\n",
    "plt.figure(figsize=(10, 3.3))\n",
    "ax = plt.subplot(111)\n",
    "sns.barplot(\n",
    "    hue=\"Nb input genes\",\n",
    "    y=\"ari\",\n",
    "    x=\"dataset\",\n",
    "    data=df[df[\"dataset\"].isin(datasets)],\n",
    "    ax=ax,\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5,\n",
    ")\n",
    "plt.ylabel(\"ARI\")\n",
    "plt.xlabel(\"\")\n",
    "plt.legend(title= \"Nb input genes\",bbox_to_anchor=(1, 1))\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{path}diagrams/real_input_size.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['10X PBMC (2100)',\n",
    "       'Mouse ES\\nCell (2100)', 'Worm Neuron\\nCell (2100)',\n",
    "       'Mouse Bladder\\n Cell (2100)']\n",
    "plt.figure(figsize=(10, 3.3))\n",
    "ax = plt.subplot(111)\n",
    "sns.barplot(\n",
    "    hue=\"Nb input genes\",\n",
    "    y=\"ari\",\n",
    "    x=\"dataset\",\n",
    "    data=df[df[\"dataset\"].isin(datasets)],\n",
    "    ax=ax,\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5,\n",
    ")\n",
    "plt.ylabel(\"ARI\")\n",
    "plt.xlabel(\"\")\n",
    "plt.legend(title= \"Nb input genes\",bbox_to_anchor=(1, 1))\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{path}diagrams/real_input_size_2100.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    columns=[\"dataset\", \"perc0\", \"nb_epochs\", \"exp\", \"ari\", \"run\"])\n",
    "print(df.shape)\n",
    "for dataset in files:\n",
    "\n",
    "    print(f\">>>>> Data {dataset}\")\n",
    "\n",
    "    data_mat = h5py.File(f\"{path}real_data/{dataset}.h5\", \"r\")\n",
    "    nb_genes = 1500\n",
    "    for epochs in [5, 50, 100, 300]:\n",
    "\n",
    "        X = np.array(data_mat['X'])\n",
    "        Y = np.array(data_mat['Y'])\n",
    "        perc_0 = np.where(X == 0)[0].shape[0] / (X.shape[0] * X.shape[1])\n",
    "        print(f\"Perc 0 {perc_0}\")\n",
    "        cluster_number = np.unique(Y).shape[0]\n",
    "\n",
    "        X = train.preprocess(X, nb_genes=nb_genes)\n",
    "        nb_zeros = int(0.8 * nb_genes)\n",
    "        for run in range(2):\n",
    "            torch.manual_seed(run)\n",
    "            torch.cuda.manual_seed_all(run)\n",
    "            np.random.seed(run)\n",
    "            random.seed(run)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "            dresults = train.train(\n",
    "                X,\n",
    "                cluster_number,\n",
    "                dataset,\n",
    "                Y,\n",
    "                n_ensemble=1,\n",
    "                epochs=epochs,\n",
    "                nb_zeros=nb_zeros,\n",
    "                save_to=f\"{path}output/real_data/epochs/{dataset}_{epochs}/\")\n",
    "\n",
    "            df.loc[df.shape[0]] = [\n",
    "                dataset, perc_0, epochs, 'kmeans_representation_0',\n",
    "                dresults['kmeans_representation_0'], run\n",
    "            ]\n",
    "            df.loc[df.shape[0]] = [\n",
    "                dataset, perc_0, epochs, 'leiden_representation_0',\n",
    "                dresults['leiden_representation_0'], run\n",
    "            ]\n",
    "\n",
    "            print(dresults)\n",
    "            df.to_pickle(f\"{path}output/pickle_results/real_data_epochs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{path}output/pickle_results/real_data_epochs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = {\n",
    "    '10X_PBMC': '10X PBMC',\n",
    "    '10X_PBMC_select_2100': '10X PBMC (2100)',\n",
    "    'mouse_ES_cell': 'Mouse ES\\nCell',\n",
    "    'mouse_ES_cell_select_2100': 'Mouse ES\\nCell (2100)',\n",
    "    'worm_neuron_cell_select_2100': 'Worm Neuron\\nCell (2100)',\n",
    "    'worm_neuron_cell': 'Worm Neuron\\nCell',\n",
    "    'mouse_bladder_cell': 'Mouse Bladder\\nCell',\n",
    "    'mouse_bladder_cell_select_2100': 'Mouse Bladder\\n Cell (2100)'\n",
    "}\n",
    "\n",
    "df[\"dataset\"] = df[\"dataset\"].apply(lambda x: dataset_names[x])\n",
    "\n",
    "df = df.rename(columns = {\"nb_epochs\": \"Nb epochs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "datasets = ['10X PBMC',  'Mouse ES\\nCell','Worm Neuron\\nCell', 'Mouse Bladder\\nCell']\n",
    "plt.figure(figsize=(7, 3))\n",
    "ax = plt.subplot(111)\n",
    "sns.barplot(\n",
    "    hue=\"Nb epochs\",\n",
    "    y=\"ari\",\n",
    "    x=\"dataset\",\n",
    "    data=df[df[\"dataset\"].isin(datasets)],\n",
    "    ax=ax,\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5,\n",
    ")\n",
    "plt.ylabel(\"ARI\")\n",
    "plt.xlabel(\"\")\n",
    "plt.legend(title =\"Number of epochs\",bbox_to_anchor=(1, 1))\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{path}diagrams/real_nb_epochs.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
