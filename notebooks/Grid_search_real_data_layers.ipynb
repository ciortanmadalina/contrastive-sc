{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original implementation of Contrastive-sc method\n",
    "(https://github.com/ciortanmadalina/contrastive-sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/scanpy/api/__init__.py:7: FutureWarning: \n",
      "\n",
      "In a future version of Scanpy, `scanpy.api` will be removed.\n",
      "Simply use `import scanpy as sc` and `import scanpy.external as sce` instead.\n",
      "\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import st_loss\n",
    "\n",
    "import h5py\n",
    "import scipy as sp\n",
    "import scanpy.api as sc\n",
    "from collections import Counter\n",
    "import random\n",
    "import utils\n",
    "\n",
    "import pickle\n",
    "\n",
    "import train\n",
    "import os\n",
    "import glob2\n",
    "plt.ion()\n",
    "plt.show()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../\"\n",
    "files = glob2.glob(f'{path}real_data/*.h5')\n",
    "files = [f[len(f\"'{path}real_data\"):-3] for f in files]\n",
    "files = [ 'Quake_10x_Spleen',\n",
    "    'Quake_Smart-seq2_Trachea',\n",
    " 'Quake_Smart-seq2_Diaphragm',\n",
    "\n",
    " 'Young',\n",
    " 'mouse_ES_cell',\n",
    " 'Adam',\n",
    " 'Quake_10x_Bladder',\n",
    " 'Quake_Smart-seq2_Lung',\n",
    " 'Quake_10x_Limb_Muscle',\n",
    " 'worm_neuron_cell',\n",
    " 'mouse_bladder_cell',\n",
    " 'Romanov',\n",
    " 'Quake_Smart-seq2_Limb_Muscle',\n",
    " 'Muraro',\n",
    " '10X_PBMC'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sczi = pd.read_pickle(f\"../output/pickle_results/real_data/real_data_sczi.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>nb_genes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quake_Smart-seq2_Trachea</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quake_Smart-seq2_Diaphragm</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quake_10x_Spleen</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Young</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mouse_ES_cell</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      dataset nb_genes\n",
       "0    Quake_Smart-seq2_Trachea      500\n",
       "1  Quake_Smart-seq2_Diaphragm     1000\n",
       "2            Quake_10x_Spleen      500\n",
       "3                       Young     1000\n",
       "4               mouse_ES_cell     1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal = pd.read_pickle(f\"{path}output/pickle_results/real_data/optimal_input_size.pkl\")\n",
    "optimal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle(f\"{path}output/pickle_results/real_data/real_data_layers.pkl\")\n",
    "df = pd.read_pickle(f\"{path}output/pickle_results/real_data/real_data_layers_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Data Quake_10x_Spleen\n",
      "SCZI  0.9207243162607069\n",
      "(9552, 23341) (9552, 23341) keeping 500 genes\n",
      "...(9552, 23341) (9552, 23341) keeping 500 genes\n",
      "...(9552, 23341) (9552, 23341) keeping 500 genes\n",
      "...>>>>> Data Quake_Smart-seq2_Trachea\n",
      "SCZI  0.8258284521205065\n",
      "(1350, 23341) (1350, 23341) keeping 500 genes\n",
      "...(1350, 23341) (1350, 23341) keeping 500 genes\n",
      "...(1350, 23341) (1350, 23341) keeping 500 genes\n",
      "...>>>>> Data Quake_Smart-seq2_Diaphragm\n",
      "SCZI  0.9596701189611787\n",
      "(870, 23341) (870, 23341) keeping 1000 genes\n",
      "...(870, 23341) (870, 23341) keeping 1000 genes\n",
      "...(870, 23341) (870, 23341) keeping 1000 genes\n",
      "...>>>>> Data Young\n",
      "SCZI  0.6966379900869195\n",
      "(5685, 33658) (5685, 33658) keeping 1000 genes\n",
      "...(5685, 33658) (5685, 33658) keeping 1000 genes\n",
      "...(5685, 33658) (5685, 33658) keeping 1000 genes\n",
      "...>>>>> Data mouse_ES_cell\n",
      "SCZI  0.8004502714264402\n",
      "(2717, 24175) (2717, 24175) keeping 1000 genes\n",
      "...(2717, 24175) (2717, 24175) keeping 1000 genes\n",
      "...(2717, 24175) (2717, 24175) keeping 1000 genes\n",
      "...>>>>> Data Adam\n",
      "SCZI  0.8632277666545504\n",
      "(3660, 23797) (3660, 23797) keeping 500 genes\n",
      "...(3660, 23797) (3660, 23797) keeping 500 genes\n",
      "...(3660, 23797) (3660, 23797) keeping 500 genes\n",
      "...>>>>> Data Quake_10x_Bladder\n",
      "SCZI  0.9828247498197693\n",
      "(2500, 23341) (2500, 23341) keeping 500 genes\n",
      "...(2500, 23341) (2500, 23341) keeping 500 genes\n",
      "...(2500, 23341) (2500, 23341) keeping 500 genes\n",
      "...>>>>> Data Quake_Smart-seq2_Lung\n",
      "SCZI  0.754207987444416\n",
      "(1676, 23341) (1676, 23341) keeping 1000 genes\n",
      "...(1676, 23341) (1676, 23341) keeping 1000 genes\n",
      "...(1676, 23341) (1676, 23341) keeping 1000 genes\n",
      "...>>>>> Data Quake_10x_Limb_Muscle\n",
      "SCZI  0.9609079013375856\n",
      "(3909, 23341) (3909, 23341) keeping 500 genes\n",
      "...(3909, 23341) (3909, 23341) keeping 500 genes\n",
      "...(3909, 23341) (3909, 23341) keeping 500 genes\n",
      "...>>>>> Data worm_neuron_cell\n",
      "SCZI  0.06355801295995496\n",
      "(4186, 13488) (4186, 13488) keeping 5000 genes\n",
      "...(4186, 13488) (4186, 13488) keeping 5000 genes\n",
      "...(4186, 13488) (4186, 13488) keeping 5000 genes\n",
      "...>>>>> Data mouse_bladder_cell\n",
      "SCZI  0.44351906948034386\n",
      "(2746, 20670) (2746, 20670) keeping 1500 genes\n",
      "...(2746, 20670) (2746, 20670) keeping 1500 genes\n",
      "...(2746, 20670) (2746, 20670) keeping 1500 genes\n",
      "...>>>>> Data Romanov\n",
      "SCZI  0.7211879386643121\n",
      "(2881, 21143) (2881, 21143) keeping 500 genes\n",
      "...(2881, 21143) (2881, 21143) keeping 500 genes\n",
      "...(2881, 21143) (2881, 21143) keeping 500 genes\n",
      "...>>>>> Data Quake_Smart-seq2_Limb_Muscle\n",
      "SCZI  0.9738741466572893\n",
      "(1090, 23341) (1090, 23341) keeping 1000 genes\n",
      "...(1090, 23341) (1090, 23341) keeping 1000 genes\n",
      "...(1090, 23341) (1090, 23341) keeping 1000 genes\n",
      "...>>>>> Data Muraro\n",
      "SCZI  0.7263895607362582\n",
      "(2122, 19046) (2122, 19046) keeping 1000 genes\n",
      "...(2122, 19046) (2122, 19046) keeping 1000 genes\n",
      "...(2122, 19046) (2122, 19046) keeping 1000 genes\n",
      "...>>>>> Data 10X_PBMC\n",
      "SCZI  0.5902722091957062\n",
      "(4271, 16653) (4271, 16653) keeping 500 genes\n",
      "...(4271, 16653) (4271, 16653) keeping 500 genes\n",
      "...(4271, 16653) (4271, 16653) keeping 500 genes\n",
      "..."
     ]
    }
   ],
   "source": [
    "# df = pd.DataFrame()\n",
    "lr = 0.4\n",
    "for dataset in files:\n",
    "\n",
    "    print(f\">>>>> Data {dataset}\")\n",
    "    print(\"SCZI \", sczi[sczi[\"dataset\"] == dataset][\"ARI\"].mean())\n",
    "    data_mat = h5py.File(f\"{path}real_data/{dataset}.h5\", \"r\")\n",
    "    X = np.array(data_mat['X'])\n",
    "    Y = np.array(data_mat['Y'])\n",
    "    nb_genes = optimal[optimal[\"dataset\"] == dataset][\"nb_genes\"].values[0]\n",
    "\n",
    "    for temperature in [0.07]:\n",
    "        for dropout in [0.9,\n",
    "#                         0.7, 0.2, 0.5 \n",
    "                       ]:\n",
    "\n",
    "            for layers in [ \n",
    "#                 [200, 40, 2], [10],[50, 10], [200, 40, 10], [200, 40, 20, 10],\n",
    "#                 [2], [20], [40], [60], [100],\n",
    "#                 [50, 2], [50, 20], [50, 40], [80, 60], [100, 100],\n",
    "#                 [200, 40, 80],  [200, 20, 60],[200, 40, 60, 40], [200, 40, 60, 60],\n",
    "#                 [200, 100, 100], [200, 100, 60], [200, 40, 40], [200, 40, 60],\n",
    "#                 [100, 60, 40],\n",
    "#                 [200, 100, 60, 40], [200, 60, 40, 20], [100, 80, 60, 50],\n",
    "                [300, 40, 60], [300, 60, 60], [300, 40, 40],\n",
    "\n",
    "                \n",
    "#                     [200, 60, 40, 2],[200, 60, 2], [60, 2], [2],\n",
    "#                     [200, 60, 60]\n",
    "#                     [200, 100, 100], [200, 40, 100], [200, 40, 40], [200, 40, 60]\n",
    "#                     [200, 100, 100, 100],[200, 80, 100], [100, 100], [100],\n",
    "#                     [200, 100, 80, 80],[200, 80, 80], [100, 80], [80],\n",
    "#                     [200, 100, 60, 60],[200, 80, 60], [100, 60], [60],\n",
    "#                     [200, 60, 40, 40],[200, 60, 40], [60, 40], [40],\n",
    "#                     [200, 60, 40, 20],[200, 60, 20], [60, 20], [20],\n",
    "                          ]:\n",
    "                data_mat = h5py.File(f\"{path}real_data/{dataset}.h5\", \"r\")\n",
    "                X = np.array(data_mat['X'])\n",
    "                Y = np.array(data_mat['Y'])\n",
    "                cluster_number = np.unique(Y).shape[0]\n",
    "\n",
    "                X = train.preprocess(X, nb_genes=nb_genes)\n",
    "\n",
    "                for run in range(3):\n",
    "                    torch.manual_seed(run)\n",
    "                    torch.cuda.manual_seed_all(run)\n",
    "                    np.random.seed(run)\n",
    "                    random.seed(run)\n",
    "                    torch.backends.cudnn.deterministic = True\n",
    "                    torch.backends.cudnn.benchmark = False\n",
    "                    dresults = train.run(X,\n",
    "                                         cluster_number,\n",
    "                                         dataset,\n",
    "                                         Y=Y,\n",
    "                                         nb_epochs=30,\n",
    "                                         lr=lr,\n",
    "                                         temperature=temperature,\n",
    "                                         dropout=dropout,\n",
    "                                         \n",
    "                                         layers=layers,\n",
    "                                         save_to=f\"{path}output/real_data/{run}/\",\n",
    "                                         save_pred = False)\n",
    "                    dresults[\"nb_genes\"] = nb_genes\n",
    "                    dresults[\"dropout\"] = dropout\n",
    "                    dresults[\"lr\"] = lr\n",
    "                    dresults[\"layers\"] = str(layers)\n",
    "                    dresults[\"run\"] = run\n",
    "                    print(f\".\", end = \"\")\n",
    "                    df = df.append(dresults, ignore_index=True)\n",
    "\n",
    "                    df.to_pickle(f\"{path}output/pickle_results/real_data/real_data_layers_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.layers.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARI       0.752219\n",
       "NMI       0.780598\n",
       "sil       0.256274\n",
       "run       1.000000\n",
       "time    189.880156\n",
       "cal     596.273096\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sczi = pd.read_pickle(f\"../output/pickle_results/real_data/real_data_sczi.pkl\")\n",
    "sczi = sczi[sczi[\"dataset\"].isin(files)]\n",
    "sczi.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers</th>\n",
       "      <th>lr</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[100, 100]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.769378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[100, 60, 40]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.763490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[100, 80, 60, 50]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.766125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[100]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.731138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[10]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.749402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 100, 100]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.756084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 100, 60, 40]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.751667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 100, 60]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.763108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 20, 60]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.762309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 40, 10]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.735698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 40, 20, 10]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.729018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 40, 2]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.533360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 40, 40]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.757692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 40, 60, 40]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.764175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 40, 60, 60]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.754944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 40, 60]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.771789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 40, 80]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.767178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[200, 60, 40, 20]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.755745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[20]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.758565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[2]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.540770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[40]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.746133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[50, 10]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.710114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[50, 20]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.758853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[50, 2]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.465332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[50, 40]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.753225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[60]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.732374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[80, 60]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dropout                      0.9\n",
       "layers             lr           \n",
       "[100, 100]         0.4  0.769378\n",
       "[100, 60, 40]      0.4  0.763490\n",
       "[100, 80, 60, 50]  0.4  0.766125\n",
       "[100]              0.4  0.731138\n",
       "[10]               0.4  0.749402\n",
       "[200, 100, 100]    0.4  0.756084\n",
       "[200, 100, 60, 40] 0.4  0.751667\n",
       "[200, 100, 60]     0.4  0.763108\n",
       "[200, 20, 60]      0.4  0.762309\n",
       "[200, 40, 10]      0.4  0.735698\n",
       "[200, 40, 20, 10]  0.4  0.729018\n",
       "[200, 40, 2]       0.4  0.533360\n",
       "[200, 40, 40]      0.4  0.757692\n",
       "[200, 40, 60, 40]  0.4  0.764175\n",
       "[200, 40, 60, 60]  0.4  0.754944\n",
       "[200, 40, 60]      0.4  0.771789\n",
       "[200, 40, 80]      0.4  0.767178\n",
       "[200, 60, 40, 20]  0.4  0.755745\n",
       "[20]               0.4  0.758565\n",
       "[2]                0.4  0.540770\n",
       "[40]               0.4  0.746133\n",
       "[50, 10]           0.4  0.710114\n",
       "[50, 20]           0.4  0.758853\n",
       "[50, 2]            0.4  0.465332\n",
       "[50, 40]           0.4  0.753225\n",
       "[60]               0.4  0.732374\n",
       "[80, 60]           0.4  0.760000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_pickle(f\"../output/pickle_results/real_data/real_data_layers.pkl\")\n",
    "df = df[df[\"dataset\"].isin(files)]\n",
    "r = df.groupby([ \"layers\", \"dropout\", \"lr\"])[\"kmeans_ari_0\"].mean().unstack([\"layers\", \"lr\"]).T\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layers</th>\n",
       "      <th>lr</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[100, 100]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.769378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[100]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.731138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[20]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.758565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[2]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.540770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[40]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.746133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[50, 20]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.758853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[50, 2]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.465332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[50, 40]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.753225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[60]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.732374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[80, 60]</th>\n",
       "      <th>0.4</th>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dropout              0.9\n",
       "layers     lr           \n",
       "[100, 100] 0.4  0.769378\n",
       "[100]      0.4  0.731138\n",
       "[20]       0.4  0.758565\n",
       "[2]        0.4  0.540770\n",
       "[40]       0.4  0.746133\n",
       "[50, 20]   0.4  0.758853\n",
       "[50, 2]    0.4  0.465332\n",
       "[50, 40]   0.4  0.753225\n",
       "[60]       0.4  0.732374\n",
       "[80, 60]   0.4  0.760000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_pickle(f\"../output/pickle_results/real_data/real_data_layers.pkl\")\n",
    "df = df[df[\"dataset\"].isin(files)]\n",
    "r = df.groupby([ \"layers\", \"dropout\", \"lr\"])[\"kmeans_ari_0\"].mean().unstack([\"layers\", \"lr\"]).T\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle(f\"../output/pickle_results/real_data/real_data_1model.pkl\")\n",
    "df.groupby([\"temperature\", \"layers\", \"dropout\", \"lr\"])[\"kmeans_ari_0\"].mean().unstack([\"layers\", \"lr\"]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = df[(df[\"layers\"]==\"[40]\")\n",
    "#        &(df[\"temperature\"]==0.01)\n",
    "#        &(df[\"lr\"]==1e-5)\n",
    "#        &(df[\"dropout\"]==0.9)\n",
    "#       ]\n",
    "r = df[(df[\"layers\"]==\"[200, 100, 30, 30]\")\n",
    "       &(df[\"temperature\"]==0.07)\n",
    "       &(df[\"lr\"]==1e-5)\n",
    "       &(df[\"dropout\"]==0.9)\n",
    "      ]\n",
    "\n",
    "\n",
    "r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = pd.merge(r, sczi, on=[\"dataset\", \"run\"])[[\n",
    "    \"dataset\", \"kmeans_ari_0\", \"ARI\", \"kmeans_nmi_0\", \"NMI\"\n",
    "]].rename(columns = {\"kmeans_ari_0\": \"contrative-sc\", \"ARI\": \"sczi\"})\n",
    "comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb =pd.melt(comb, id_vars=[\"dataset\"], value_vars=[\"contrative-sc\", \"sczi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot( data = comb, y=\"value\", x = \"variable\")\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x = \"dataset\", data = comb, y=\"value\", hue = \"variable\")\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"dataset\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    columns=[\"dataset\", \"perc0\", \"nb_genes\", \"exp\", \"ari\", \"run\"])\n",
    "print(df.shape)\n",
    "for dataset in files:\n",
    "\n",
    "    print(f\">>>>> Data {dataset}\")\n",
    "\n",
    "    data_mat = h5py.File(f\"{path}real_data/{dataset}.h5\", \"r\")\n",
    "    for run in range(2):\n",
    "        torch.manual_seed(run)\n",
    "        torch.cuda.manual_seed_all(run)\n",
    "        np.random.seed(run)\n",
    "        random.seed(run)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        for nb_genes in [100, 200, 500, 1000, 1500, 2000, 5000, 8000]:\n",
    "\n",
    "            X = np.array(data_mat['X'])\n",
    "            Y = np.array(data_mat['Y'])\n",
    "            perc_0 = np.where(X == 0)[0].shape[0] / (X.shape[0] * X.shape[1])\n",
    "            print(f\"Perc 0 {perc_0}\")\n",
    "            cluster_number = np.unique(Y).shape[0]\n",
    "\n",
    "            X = train.preprocess(X, nb_genes=nb_genes)\n",
    "            nb_zeros = int(0.8 * nb_genes)\n",
    "            dresults = train.train(\n",
    "                X,\n",
    "                cluster_number,\n",
    "                dataset,\n",
    "                Y,\n",
    "                \n",
    "                epochs=100,\n",
    "                nb_zeros=nb_zeros,\n",
    "                save_to=f\"{path}output/real_data/inputs/{dataset}_{nb_genes}/\")\n",
    "\n",
    "            #         df.loc[df.shape[0]] = [\n",
    "            #                 dataset, perc_0, nb_genes, 'kmeans_representation_0',dresults['kmeans_representation_0']\n",
    "            #             ]\n",
    "            df.loc[df.shape[0]] = [\n",
    "                dataset, perc_0, nb_genes, 'leiden_representation_0',\n",
    "                dresults['leiden_representation_0'], run]\n",
    "\n",
    "#             pxt = PCA(2).fit_transform(X)\n",
    "#             dresults[\"original\"] = utils.evaluate(X, Y, cluster_number)[1]\n",
    "#             dresults[\"pca\"] = utils.evaluate(pxt, Y, cluster_number)[1]\n",
    "            print(dresults)\n",
    "    df.to_pickle(f\"{path}output/pickle_results/real_data_input_size.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{path}output/pickle_results/real_data_input_size.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"nb_genes\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = {\n",
    "    '10X_PBMC': '10X PBMC',\n",
    "    '10X_PBMC_select_2100': '10X PBMC (2100)',\n",
    "    'mouse_ES_cell': 'Mouse ES\\nCell',\n",
    "    'mouse_ES_cell_select_2100': 'Mouse ES\\nCell (2100)',\n",
    "    'worm_neuron_cell_select_2100': 'Worm Neuron\\nCell (2100)',\n",
    "    'worm_neuron_cell': 'Worm Neuron\\nCell',\n",
    "    'mouse_bladder_cell': 'Mouse Bladder\\nCell',\n",
    "    'mouse_bladder_cell_select_2100': 'Mouse Bladder\\n Cell (2100)'\n",
    "}\n",
    "\n",
    "df[\"dataset\"] = df[\"dataset\"].apply(lambda x: dataset_names[x])\n",
    "\n",
    "df = df.rename(columns = {\"nb_genes\": \"Nb input genes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dataset\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "datasets = ['10X PBMC',  'Mouse ES\\nCell','Worm Neuron\\nCell', 'Mouse Bladder\\nCell']\n",
    "plt.figure(figsize=(10, 3.3))\n",
    "ax = plt.subplot(111)\n",
    "sns.barplot(\n",
    "    hue=\"Nb input genes\",\n",
    "    y=\"ari\",\n",
    "    x=\"dataset\",\n",
    "    data=df[df[\"dataset\"].isin(datasets)],\n",
    "    ax=ax,\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5,\n",
    ")\n",
    "plt.ylabel(\"ARI\")\n",
    "plt.xlabel(\"\")\n",
    "plt.legend(title= \"Nb input genes\",bbox_to_anchor=(1, 1))\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{path}diagrams/real_input_size.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['10X PBMC (2100)',\n",
    "       'Mouse ES\\nCell (2100)', 'Worm Neuron\\nCell (2100)',\n",
    "       'Mouse Bladder\\n Cell (2100)']\n",
    "plt.figure(figsize=(10, 3.3))\n",
    "ax = plt.subplot(111)\n",
    "sns.barplot(\n",
    "    hue=\"Nb input genes\",\n",
    "    y=\"ari\",\n",
    "    x=\"dataset\",\n",
    "    data=df[df[\"dataset\"].isin(datasets)],\n",
    "    ax=ax,\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5,\n",
    ")\n",
    "plt.ylabel(\"ARI\")\n",
    "plt.xlabel(\"\")\n",
    "plt.legend(title= \"Nb input genes\",bbox_to_anchor=(1, 1))\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{path}diagrams/real_input_size_2100.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    columns=[\"dataset\", \"perc0\", \"nb_epochs\", \"exp\", \"ari\", \"run\"])\n",
    "print(df.shape)\n",
    "for dataset in files:\n",
    "\n",
    "    print(f\">>>>> Data {dataset}\")\n",
    "\n",
    "    data_mat = h5py.File(f\"{path}real_data/{dataset}.h5\", \"r\")\n",
    "    nb_genes = 1500\n",
    "    for epochs in [5, 50, 100, 300]:\n",
    "\n",
    "        X = np.array(data_mat['X'])\n",
    "        Y = np.array(data_mat['Y'])\n",
    "        perc_0 = np.where(X == 0)[0].shape[0] / (X.shape[0] * X.shape[1])\n",
    "        print(f\"Perc 0 {perc_0}\")\n",
    "        cluster_number = np.unique(Y).shape[0]\n",
    "\n",
    "        X = train.preprocess(X, nb_genes=nb_genes)\n",
    "        nb_zeros = int(0.8 * nb_genes)\n",
    "        for run in range(2):\n",
    "            torch.manual_seed(run)\n",
    "            torch.cuda.manual_seed_all(run)\n",
    "            np.random.seed(run)\n",
    "            random.seed(run)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "\n",
    "            dresults = train.train(\n",
    "                X,\n",
    "                cluster_number,\n",
    "                dataset,\n",
    "                Y,\n",
    "                \n",
    "                epochs=epochs,\n",
    "                nb_zeros=nb_zeros,\n",
    "                save_to=f\"{path}output/real_data/epochs/{dataset}_{epochs}/\")\n",
    "\n",
    "            df.loc[df.shape[0]] = [\n",
    "                dataset, perc_0, epochs, 'kmeans_representation_0',\n",
    "                dresults['kmeans_representation_0'], run\n",
    "            ]\n",
    "            df.loc[df.shape[0]] = [\n",
    "                dataset, perc_0, epochs, 'leiden_representation_0',\n",
    "                dresults['leiden_representation_0'], run\n",
    "            ]\n",
    "\n",
    "            print(dresults)\n",
    "            df.to_pickle(f\"{path}output/pickle_results/real_data_epochs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{path}output/pickle_results/real_data_epochs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = {\n",
    "    '10X_PBMC': '10X PBMC',\n",
    "    '10X_PBMC_select_2100': '10X PBMC (2100)',\n",
    "    'mouse_ES_cell': 'Mouse ES\\nCell',\n",
    "    'mouse_ES_cell_select_2100': 'Mouse ES\\nCell (2100)',\n",
    "    'worm_neuron_cell_select_2100': 'Worm Neuron\\nCell (2100)',\n",
    "    'worm_neuron_cell': 'Worm Neuron\\nCell',\n",
    "    'mouse_bladder_cell': 'Mouse Bladder\\nCell',\n",
    "    'mouse_bladder_cell_select_2100': 'Mouse Bladder\\n Cell (2100)'\n",
    "}\n",
    "\n",
    "df[\"dataset\"] = df[\"dataset\"].apply(lambda x: dataset_names[x])\n",
    "\n",
    "df = df.rename(columns = {\"nb_epochs\": \"Nb epochs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "datasets = ['10X PBMC',  'Mouse ES\\nCell','Worm Neuron\\nCell', 'Mouse Bladder\\nCell']\n",
    "plt.figure(figsize=(7, 3))\n",
    "ax = plt.subplot(111)\n",
    "sns.barplot(\n",
    "    hue=\"Nb epochs\",\n",
    "    y=\"ari\",\n",
    "    x=\"dataset\",\n",
    "    data=df[df[\"dataset\"].isin(datasets)],\n",
    "    ax=ax,\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5,\n",
    ")\n",
    "plt.ylabel(\"ARI\")\n",
    "plt.xlabel(\"\")\n",
    "plt.legend(title =\"Number of epochs\",bbox_to_anchor=(1, 1))\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{path}diagrams/real_nb_epochs.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
