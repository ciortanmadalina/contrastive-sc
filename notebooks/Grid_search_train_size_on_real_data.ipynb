{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original implementation of Contrastive-sc method\n",
    "(https://github.com/ciortanmadalina/contrastive-sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/scanpy/api/__init__.py:7: FutureWarning: \n",
      "\n",
      "In a future version of Scanpy, `scanpy.api` will be removed.\n",
      "Simply use `import scanpy as sc` and `import scanpy.external as sce` instead.\n",
      "\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import st_loss\n",
    "import time\n",
    "import h5py\n",
    "import scipy as sp\n",
    "import scanpy.api as sc\n",
    "from collections import Counter\n",
    "import random\n",
    "import utils\n",
    "\n",
    "import pickle\n",
    "\n",
    "import train\n",
    "import os\n",
    "import glob2\n",
    "plt.ion()\n",
    "plt.show()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quake_Smart-seq2_Trachea',\n",
       " 'Quake_Smart-seq2_Diaphragm',\n",
       " 'Quake_10x_Spleen',\n",
       " 'Young',\n",
       " 'mouse_ES_cell',\n",
       " 'Adam',\n",
       " 'Quake_10x_Bladder',\n",
       " 'Quake_Smart-seq2_Lung',\n",
       " 'Quake_10x_Limb_Muscle',\n",
       " 'worm_neuron_cell',\n",
       " 'mouse_bladder_cell',\n",
       " 'Romanov',\n",
       " 'Quake_Smart-seq2_Limb_Muscle',\n",
       " 'Muraro',\n",
       " '10X_PBMC']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../\"\n",
    "category = \"real_data\"\n",
    "files = glob2.glob(f'{path}{category}/*.h5')\n",
    "files = [f[len(f\"'{path}{category}\"):-3] for f in files]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>nb_genes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quake_Smart-seq2_Trachea</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quake_Smart-seq2_Diaphragm</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quake_10x_Spleen</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Young</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mouse_ES_cell</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      dataset nb_genes\n",
       "0    Quake_Smart-seq2_Trachea      500\n",
       "1  Quake_Smart-seq2_Diaphragm     1000\n",
       "2            Quake_10x_Spleen      500\n",
       "3                       Young     1000\n",
       "4               mouse_ES_cell     1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal = pd.read_pickle(f\"{path}output/pickle_results/real_data/optimal_input_size.pkl\")\n",
    "optimal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sczi = pd.read_pickle(f\"../output/pickle_results/real_data/real_data_sczi.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Data Quake_Smart-seq2_Trachea\n",
      "SCZI  0.8258284521205065\n",
      "(1350, 23341) (1350, 23341) keeping 500 genes\n",
      ">>>>> Data Quake_Smart-seq2_Diaphragm\n",
      "SCZI  0.9596701189611787\n",
      "(870, 23341) (870, 23341) keeping 1000 genes\n",
      "WARNING: n_obs too small: adjusting to `n_neighbors = 109`\n",
      "WARNING: n_obs too small: adjusting to `n_neighbors = 109`\n",
      "WARNING: n_obs too small: adjusting to `n_neighbors = 109`\n",
      ">>>>> Data Quake_10x_Spleen\n",
      "SCZI  0.9207243162607069\n",
      "(9552, 23341) (9552, 23341) keeping 500 genes\n",
      ">>>>> Data Young\n",
      "SCZI  0.6966379900869195\n",
      "(5685, 33658) (5685, 33658) keeping 1000 genes\n",
      ">>>>> Data mouse_ES_cell\n",
      "SCZI  0.8004502714264402\n",
      "(2717, 24175) (2717, 24175) keeping 1000 genes\n",
      ">>>>> Data Adam\n",
      "SCZI  0.8632277666545504\n",
      "(3660, 23797) (3660, 23797) keeping 500 genes\n",
      ">>>>> Data Quake_10x_Bladder\n",
      "SCZI  0.9828247498197693\n",
      "(2500, 23341) (2500, 23341) keeping 500 genes\n",
      ">>>>> Data Quake_Smart-seq2_Lung\n",
      "SCZI  0.754207987444416\n",
      "(1676, 23341) (1676, 23341) keeping 1000 genes\n",
      ">>>>> Data Quake_10x_Limb_Muscle\n",
      "SCZI  0.9609079013375856\n",
      "(3909, 23341) (3909, 23341) keeping 500 genes\n",
      ">>>>> Data worm_neuron_cell\n",
      "SCZI  0.06355801295995496\n",
      "(4186, 13488) (4186, 13488) keeping 5000 genes\n",
      ">>>>> Data mouse_bladder_cell\n",
      "SCZI  0.44351906948034386\n",
      "(2746, 20670) (2746, 20670) keeping 1500 genes\n",
      ">>>>> Data Romanov\n",
      "SCZI  0.7211879386643121\n",
      "(2881, 21143) (2881, 21143) keeping 500 genes\n",
      ">>>>> Data Quake_Smart-seq2_Limb_Muscle\n",
      "SCZI  0.9738741466572893\n",
      "(1090, 23341) (1090, 23341) keeping 1000 genes\n",
      "WARNING: n_obs too small: adjusting to `n_neighbors = 137`\n",
      "WARNING: n_obs too small: adjusting to `n_neighbors = 137`\n",
      "WARNING: n_obs too small: adjusting to `n_neighbors = 137`\n",
      ">>>>> Data Muraro\n",
      "SCZI  0.7263895607362582\n",
      "(2122, 19046) (2122, 19046) keeping 1000 genes\n",
      ">>>>> Data 10X_PBMC\n",
      "SCZI  0.5902722091957062\n",
      "(4271, 16653) (4271, 16653) keeping 500 genes\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "dropout = 0.9\n",
    "lr = 0.4\n",
    "layers = [200, 40, 60]\n",
    "temperature = 0.07\n",
    "for dataset in files:\n",
    "\n",
    "    print(f\">>>>> Data {dataset}\")\n",
    "    print(\"SCZI \", sczi[sczi[\"dataset\"] == dataset][\"ARI\"].mean())\n",
    "    data_mat = h5py.File(f\"{path}real_data/{dataset}.h5\", \"r\")\n",
    "\n",
    "    \n",
    "    nb_genes = optimal[optimal[\"dataset\"] == dataset][\"nb_genes\"].values[0]\n",
    "    data_mat = h5py.File(f\"{path}real_data/{dataset}.h5\", \"r\")\n",
    "    X = np.array(data_mat['X'])\n",
    "    Y = np.array(data_mat['Y'])\n",
    "    cluster_number = np.unique(Y).shape[0]\n",
    "\n",
    "    X = train.preprocess(X, nb_genes=nb_genes)\n",
    "    for train_size in [ 1, 0.75, 0.5, 0.25\n",
    "    ]:\n",
    "        for run in range(3):\n",
    "            torch.manual_seed(run)\n",
    "            torch.cuda.manual_seed_all(run)\n",
    "            np.random.seed(run)\n",
    "            random.seed(run)\n",
    "            if train_size == 1:\n",
    "                X_train = X\n",
    "                y_train = Y\n",
    "            else:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, Y, train_size=train_size, random_state=run)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            torch.backends.cudnn.benchmark = False\n",
    "            start = time.time()\n",
    "            dresults = train.run(X_train,\n",
    "                                 cluster_number,\n",
    "                                 dataset,\n",
    "                                 Y=y_train,\n",
    "                                 nb_epochs=30,\n",
    "                                 lr=lr,\n",
    "                                 temperature=temperature,\n",
    "                                 dropout=dropout,\n",
    "                                 \n",
    "                                 \n",
    "                                 layers=layers,\n",
    "                                 save_to=f\"{path}output/{category}/{run}/\",\n",
    "                                 save_pred=False)\n",
    "            elapsed = time.time() - start\n",
    "            dresults[\"temperature\"] = temperature\n",
    "            dresults[\"dropout\"] = dropout\n",
    "            dresults[\"train_size\"] = train_size\n",
    "            dresults[\"layers\"] = str(layers)\n",
    "            dresults[\"run\"] = run\n",
    "            dresults[\"time\"] = elapsed\n",
    "            #         print(f\".\", end = \"\")\n",
    "            #         print(f\"# {temperature}, {dropout}, {lr}, {layers}\",\n",
    "            #               dresults.get('COMBINED_kmeans_ari', \"\"),\n",
    "            #               dresults.get('COMBINED_leiden_ari', \"\"), dresults.get('kmeans_ari_0',\"\"),\n",
    "            #               dresults.get('leiden_ari_0', \"\"))\n",
    "            df = df.append(dresults, ignore_index=True)\n",
    "\n",
    "            df.to_pickle(\n",
    "                f\"{path}output/pickle_results/{category}/{category}_train_size.pkl\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"train_size\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()#0.686020 20 # 0.631504:10 # 0.693487 : 30 #0.685507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
