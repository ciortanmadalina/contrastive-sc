{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original implementation of Contrastive-sc method\n",
    "(https://github.com/ciortanmadalina/contrastive-sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/scanpy/api/__init__.py:7: FutureWarning: \n",
      "\n",
      "In a future version of Scanpy, `scanpy.api` will be removed.\n",
      "Simply use `import scanpy as sc` and `import scanpy.external as sce` instead.\n",
      "\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "from sklearn.metrics import (adjusted_rand_score, normalized_mutual_info_score, \n",
    "                             silhouette_score, calinski_harabasz_score)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import st_loss\n",
    "\n",
    "import h5py\n",
    "import scipy as sp\n",
    "import scanpy.api as sc\n",
    "from collections import Counter\n",
    "import random\n",
    "import utils\n",
    "import loop\n",
    "import pickle\n",
    "\n",
    "import train\n",
    "import os\n",
    "import glob2\n",
    "plt.ion()\n",
    "plt.show()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " description.xlsx\t        real_data_noise.pkl\r\n",
      " optimal_input_size.pkl         real_data_pca_kmeans.pkl\r\n",
      " real_data_1model.pkl\t       'real_data_scDeepCluster (copy).pkl'\r\n",
      " real_data_baseline.pkl         real_data_scDeepCluster.pkl\r\n",
      " real_data_baseline_cpu.pkl     real_data_scDeepCluster1.pkl\r\n",
      " real_data_combined.pkl         real_data_scanpy.pkl\r\n",
      " real_data_dataset_tuning.pkl   real_data_scedar.pkl\r\n",
      " real_data_desc.pkl\t        real_data_scrna.pkl\r\n",
      " real_data_layers.pkl\t        real_data_scvi.pkl\r\n",
      " real_data_layers_new.pkl       real_data_sczi.pkl\r\n",
      " real_data_lr.pkl\t        real_data_train_size.pkl\r\n",
      " real_data_nb_epochs.pkl        real_data_worm.pkl\r\n",
      " real_data_nb_genes.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../output/pickle_results/real_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../\"\n",
    "\n",
    "category = \"real_data\"\n",
    "\n",
    "scDeepCluster = pd.read_pickle(\n",
    "    f\"../output/pickle_results/{category}/{category}_scDeepCluster.pkl\")\n",
    "scDeepCluster1 = pd.read_pickle(\n",
    "    f\"../output/pickle_results/{category}/{category}_scDeepCluster (copy).pkl\")\n",
    "\n",
    "pd.concat([\n",
    "    scDeepCluster, scDeepCluster1[scDeepCluster1.dataset == \"Quake_10x_Spleen\"]\n",
    "]).to_pickle(\n",
    "    f\"../output/pickle_results/{category}/{category}_scDeepCluster1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scvi = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_scvi.pkl\")\n",
    "# scvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quake_Smart-seq2_Trachea', 'Quake_Smart-seq2_Diaphragm', 'Quake_10x_Spleen', 'Young', 'mouse_ES_cell', 'Adam', 'Quake_10x_Bladder', 'Quake_Smart-seq2_Lung', 'Quake_10x_Limb_Muscle', 'worm_neuron_cell', 'mouse_bladder_cell', 'Romanov', 'Quake_Smart-seq2_Limb_Muscle', 'Muraro', '10X_PBMC']\n",
      "['data_1c8', 'data_-1c4', 'data_-1c8', 'data_0c4', 'data_0c8', 'data_0c16', 'data_1.5c4', 'data_1c4', 'data_1.5c8', 'data_1.5c16', 'data_-1c16', 'data_1c16']\n",
      "['data_1c8', 'data_-1c4', 'data_-1c8', 'data_0c4', 'data_0c8', 'data_0c16', 'data_1.5c4', 'data_1c4', 'data_1.5c8', 'data_1.5c16', 'data_-1c16', 'data_1c16']\n"
     ]
    }
   ],
   "source": [
    "for category in [ \"real_data\",\n",
    "                 \"imbalanced_data\", \"balanced_data\",\n",
    "                ]:\n",
    "\n",
    "    df = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_baseline.pkl\")\n",
    "#     df.groupby([\"temperature\", \"layers\", \"dropout\", \"lr\"])[\"kmeans_ari\"].mean().unstack([\"layers\", \"lr\"])\n",
    "\n",
    "    df_k = df[[\n",
    "        'dataset',\n",
    "        'dropout',\n",
    "        'kmeans_ari',\n",
    "        'kmeans_nmi',\n",
    "        'kmeans_sil',\n",
    "        'kmeans_cal',\n",
    "        'run',\n",
    "        \"t_k\",\n",
    "        'kmeans_pred',\n",
    "    ]].rename(columns={\n",
    "        'kmeans_ari': \"ARI\",\n",
    "        'kmeans_nmi': \"NMI\",\n",
    "        'kmeans_pred': 'pred',\n",
    "        'kmeans_sil': \"sil\",\n",
    "        'kmeans_cal': \"cal\",\n",
    "        't_k': 'time'\n",
    "    })\n",
    "    df_k[\"method\"] = \"constrastive+KM\"\n",
    "\n",
    "    df_l = df[[\n",
    "        'dataset',\n",
    "        'dropout',\n",
    "        'leiden_ari',\n",
    "        'leiden_nmi',\n",
    "        'leiden_sil',\n",
    "        'leiden_cal',\n",
    "        'run',\n",
    "        't_l',\n",
    "        'leiden_pred',\n",
    "    ]].rename(columns={\n",
    "        'leiden_ari': \"ARI\",\n",
    "        'leiden_nmi': \"NMI\",\n",
    "        'leiden_pred': 'pred',\n",
    "        'leiden_sil': \"sil\",\n",
    "        'leiden_cal': \"cal\",\n",
    "        't_l': 'time'\n",
    "    })\n",
    "\n",
    "    df_l[\"method\"] = \"constrastive+LD\"\n",
    "\n",
    "    r_data = pd.read_pickle(f\"../R/{category}.pkl\")\n",
    "\n",
    "    if category == \"real_data\":\n",
    "        scDeepCluster = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_scDeepCluster1.pkl\")\n",
    "    else: \n",
    "        scDeepCluster = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_scDeepCluster.pkl\")\n",
    "    scDeepCluster[\"method\"] = \"scDeepCluster\"\n",
    "\n",
    "    sczi = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_sczi.pkl\")\n",
    "    sczi[\"method\"] = \"scziDesk\"\n",
    "\n",
    "    scedar = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_scedar.pkl\")\n",
    "    scedar[\"method\"] = \"scedar\"\n",
    "\n",
    "    scanpy = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_scanpy.pkl\")\n",
    "    scanpy[\"method\"] = \"scanpy-seurat\"\n",
    "\n",
    "    scrna = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_scrna.pkl\")\n",
    "    scrna[\"method\"] = \"scrna\"\n",
    "\n",
    "    pca_kmeans = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_pca_kmeans.pkl\")\n",
    "    pca_kmeans[\"method\"] = \"pca_kmeans\"\n",
    "    \n",
    "    scvi = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_scvi.pkl\")\n",
    "    scvi[\"method\"] = \"scvi\"\n",
    "    \n",
    "\n",
    "    desc = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_desc.pkl\")\n",
    "    desc[\"pred\"] = desc[\"pred\"].apply(lambda x: x.to_list())\n",
    "    desc[\"method\"] = \"desc\"\n",
    "\n",
    "    all_data = pd.concat([df_k, df_l, r_data, desc,pca_kmeans, sczi, \n",
    "                          scDeepCluster ,scedar, scanpy, scvi, scrna])\n",
    "    all_data = all_data.reset_index(drop = True)\n",
    "\n",
    "    all_data = all_data.rename(columns={\"sil\": \"Silhouette\", \"cal\": \"Calinski\"})\n",
    "\n",
    "    path = \"..\"\n",
    "    if category in [\"balanced_data\", \"imbalanced_data\"]:\n",
    "        files = glob2.glob(f'{path}/R/simulated_data/{category}/*.h5')\n",
    "        files = [f[len(f\"{path}/R/simulated_data/{category}/\"):-3] for f in files]\n",
    "    else:\n",
    "        files = glob2.glob(f'{path}/real_data/*.h5')\n",
    "        files = [f[len(f\"{path}/real_data/\"):-3] for f in files]\n",
    "    print(files)\n",
    "\n",
    "\n",
    "    if category in [\"imbalanced_data\", \"balanced_data\"]:\n",
    "        sc_dropout = {\n",
    "            'data_1c8': 0.3,\n",
    "            'data_-1c4': 0.08,\n",
    "            'data_-1c8': 0.08,\n",
    "            'data_0c4': 0.17,\n",
    "            'data_0c8': 0.17,\n",
    "            'data_0c16': 0.17,\n",
    "            'data_1.5c4': 0.38,\n",
    "            'data_1c4': 0.3,\n",
    "            'data_1.5c8': 0.38,\n",
    "            'data_1.5c16': 0.38,\n",
    "            'data_-1c16': 0.08,\n",
    "            'data_1c16': 0.3,\n",
    "            'data_0c32': 0.17,\n",
    "            'data_1.5c32': 0.38,\n",
    "            'data_1c32': 0.3,\n",
    "            'data_-1c32': 0.08\n",
    "        }\n",
    "        all_data[\"dropout\"] = all_data[\"dataset\"].apply(lambda x: sc_dropout[x])\n",
    "        all_data[\"nb_clust\"]= all_data[\"dataset\"].apply(lambda x: int(x.split(\"c\")[1]))\n",
    "#     ordered_methods = [\n",
    "#         'constrastive+KM',\n",
    "#         'constrastive+LD',\n",
    "#         'scziDesk',\n",
    "#         'scDeepCluster',\n",
    "#         'desc',\n",
    "#         'scanpy-seurat',\n",
    "#         'scedar',\n",
    "#         'scrna',\n",
    "#         'soup',\n",
    "#         'scvi',\n",
    "#         'raceid',\n",
    "#         'cidr',\n",
    "#         'pca_kmeans',\n",
    "#     ]\n",
    "\n",
    "    ordered_methods = [\n",
    "        'constrastive+KM',\n",
    "        'scziDesk',\n",
    "        'scDeepCluster',\n",
    "        'scrna',\n",
    "        'cidr',\n",
    "        'soup',\n",
    "        'pca_kmeans',\n",
    "        'constrastive+LD',\n",
    "        'desc',\n",
    "        'scanpy-seurat',\n",
    "        'scedar',\n",
    "        'scvi',\n",
    "        'raceid',  \n",
    "    ]\n",
    "    ordered_methods = dict(zip(ordered_methods, np.arange(len(ordered_methods))))\n",
    "\n",
    "    all_data[\"order\"] = all_data[\"method\"].apply(lambda x: ordered_methods[x])\n",
    "\n",
    "    all_data.to_pickle(f\"../output/pickle_results/{category}/{category}_combined.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     ordered_methods = [\n",
    "#         'constrastive+KM',\n",
    "#         'scziDesk',\n",
    "#         'scDeepCluster',\n",
    "#         'scrna',\n",
    "#         'cidr',\n",
    "#         'soup',\n",
    "#         'pca_kmeans',\n",
    "#         'constrastive+LD',\n",
    "#         'desc',\n",
    "#         'scanpy-seurat',\n",
    "#         'scedar',\n",
    "#         'scvi',\n",
    "#         'raceid',\n",
    "        \n",
    "        \n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"imbalanced_data\"\n",
    "# category = \"balanced_data\"\n",
    "# category = \"real_data\"\n",
    "all_data = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_combined.pkl\")\n",
    "\n",
    "# all_data[\"nb_pred_clust\"] = all_data[\"pred\"].apply(lambda x: np.unique(x).shape[0])\n",
    "# all_data[\"nb_pred_clust\"] = all_data.apply(lambda x: x[\"nb_pred_clust\"]/x[\"nb_clust\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data[all_data[\"method\"] == \"desc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "clrs = ['#C0392B', \"#F1948A\", \"#D7BDE2\", \"#8E44AD\", \"#7FB3D5\", \"#2874A6\", \"#76D7C4\", \"#117A65\",\n",
    "        '#00ff00',\n",
    "        \"#F1C40F\", \"#EB984E\", \"#839192\", \"#566573\"\n",
    "       ]\n",
    "len(clrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"imbalanced_data\"\n",
    "all_data = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_combined.pkl\")\n",
    "rank = all_data.groupby([\"dataset\", \"method\"])[\"ARI\"].mean().unstack(\"method\").round(3).T\n",
    "rank = rank.rank(ascending=False, method = \"min\")\n",
    "rankKM = rank.T[\"constrastive+KM\"]\n",
    "rankLD = rank.T[\"constrastive+LD\"]\n",
    "rankKM\n",
    "\n",
    "rank = pd.concat([rankKM, rankLD], axis = 1)\n",
    "\n",
    "rank[\"rank\"] = rank.apply(lambda x: min(x.values), axis = 1)\n",
    "\n",
    "rank = rank[\"rank\"] \n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Comparaision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 13))\n",
    "category = \"balanced_data\"\n",
    "all_data = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_combined.pkl\")\n",
    "all_data[\"label\"] =all_data.apply(lambda x : f\"dp: {x['dropout']}\\n{x['nb_clust']} clust\", axis = 1)\n",
    "all_data[\"nb_pred_clust\"] = all_data[\"pred\"].apply(lambda x: np.unique(x).shape[0])\n",
    "all_data[\"nb_pred_clust\"] = all_data.apply(lambda x: x[\"nb_pred_clust\"]/x[\"nb_clust\"], axis = 1)\n",
    "rank = all_data.groupby([\"dataset\", \"method\"])[\"ARI\"].mean().unstack(\"method\").round(3).T\n",
    "rank = rank.rank(ascending=False, method = \"min\")\n",
    "rankKM = rank.T[\"constrastive+KM\"]\n",
    "rankLD = rank.T[\"constrastive+LD\"]\n",
    "ax = plt.subplot(411)\n",
    "sns.barplot(x = \"label\", y=\"ARI\", \n",
    "                data = all_data.sort_values(by=[\"dropout\", 'nb_clust', \"order\"]),\n",
    "                hue = \"method\",\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=0.8)\n",
    "plt.xticks(fontsize=13)\n",
    "# Ranking\n",
    "seld = all_data.sort_values(by=[\"dropout\", 'nb_clust', \"order\"])[\"dataset\"].unique()\n",
    "for i, d in enumerate(seld):\n",
    "    plt.text(i-0.1, 0.98, f\"#{int(rankKM[d])}, #{int(rankLD[d])}\", fontsize=13)\n",
    "plt.legend(bbox_to_anchor=(0, 1.45), loc=2, borderaxespad=0., ncol=10, fontsize=13)\n",
    "sns.despine()\n",
    "plt.xlabel(\"\")\n",
    "plt.title(\"(a) Detailed Balanced data\")\n",
    "\n",
    "ax = plt.subplot(425)\n",
    "sns.barplot(x = \"method\", y=\"ARI\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=1.5)\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False) # labels along the bottom edge are off\n",
    "for i in range(7,13):\n",
    "    plt.text(i, 0.80, \"*\")\n",
    "plt.xlabel(\"\")\n",
    "plt.title(\"(c) Average Balanced data\")\n",
    "ax = plt.subplot(427)\n",
    "sns.barplot(x = \"method\", y=\"nb_pred_clust\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=1.5)\n",
    "plt.xticks(fontsize=13,  rotation = 70)\n",
    "plt.axhline(y=1, c = \"black\")\n",
    "plt.ylabel(\"Nb predicted clusters\")\n",
    "sns.despine()\n",
    "for i in range(7,13):\n",
    "    plt.text(i, 2, \"*\")\n",
    "plt.title(f\"(e)Balanced data - Nb predicted clusters precision\")\n",
    "plt.xlabel(\"\")\n",
    "sns.despine()\n",
    "###########################################\n",
    "category = \"imbalanced_data\"\n",
    "all_data = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_combined.pkl\")\n",
    "all_data[\"label\"] =all_data.apply(lambda x : f\"dp: {x['dropout']}\\n{x['nb_clust']} clust\", axis = 1)\n",
    "all_data[\"nb_pred_clust\"] = all_data[\"pred\"].apply(lambda x: np.unique(x).shape[0])\n",
    "all_data[\"nb_pred_clust\"] = all_data.apply(lambda x: x[\"nb_pred_clust\"]/x[\"nb_clust\"], axis = 1)\n",
    "rank = all_data.groupby([\"dataset\", \"method\"])[\"ARI\"].mean().unstack(\"method\").round(3).T\n",
    "rank = rank.rank(ascending=False, method = \"min\")\n",
    "rankKM = rank.T[\"constrastive+KM\"]\n",
    "rankLD = rank.T[\"constrastive+LD\"]\n",
    "\n",
    "ax = plt.subplot(412)\n",
    "sns.barplot(x = \"label\", y=\"ARI\", \n",
    "                data = all_data.sort_values(by=[\"dropout\", 'nb_clust', \"order\"]),\n",
    "                hue = \"method\",\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=0.8)\n",
    "# Ranking\n",
    "seld = all_data.sort_values(by=[\"dropout\", 'nb_clust', \"order\"])[\"dataset\"].unique()\n",
    "for i, d in enumerate(seld):\n",
    "    plt.text(i-0.1, 0.96, f\"#{int(rankKM[d])}, #{int(rankLD[d])}\", fontsize=13)\n",
    "    \n",
    "plt.legend([])\n",
    "sns.despine()\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(fontsize=13)\n",
    "plt.title(\"(b) Detailed Imbalanced data\")\n",
    "ax = plt.subplot(426)\n",
    "sns.barplot(x = \"method\", y=\"ARI\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=1.5)\n",
    "for i in range(7,13):\n",
    "    plt.text(i, 0.72, \"*\")\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False) # labels along the bottom edge are off\n",
    "# plt.xticks(fontsize=13, rotation = 70)\n",
    "plt.title(f\"(d)Average Imbalanced data\")\n",
    "plt.xlabel(\"\")\n",
    "sns.despine()\n",
    "\n",
    "ax = plt.subplot(428)\n",
    "sns.barplot(x = \"method\", y=\"nb_pred_clust\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "           linewidth=1.5\n",
    "           )\n",
    "plt.axhline(y=1, c = \"black\")\n",
    "plt.ylabel(\"Nb predicted clusters \")\n",
    "plt.xticks(fontsize=13,  rotation = 70)\n",
    "for i in range(7,13):\n",
    "    plt.text(i, 4, \"*\")\n",
    "plt.title(f\"(f)Imbalanced data - Nb predicted clusters precision\")\n",
    "sns.despine()\n",
    "plt.xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"../diagrams/simulated.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"real_data\"\n",
    "desc = pd.read_excel(\"../output/pickle_results/real_data/description.xlsx\")\n",
    "all_data = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_combined.pkl\")\n",
    "all_data = pd.merge(all_data, desc[[\"dataset\", \"nb_clusters\"]], on = \"dataset\")\n",
    "all_data[\"nb_pred_clust\"] = all_data[\"pred\"].apply(lambda x: np.unique(x).shape[0])\n",
    "all_data[\"nb_pred_clust\"] = all_data.apply(lambda x: x[\"nb_pred_clust\"]/x[\"nb_clusters\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.groupby(\"method\").agg({\"time\": \"mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "letters = [\"(a)\", \"(b)\", \"(c)\", \"(d)\",\n",
    "           \"(e)\", \"(f)\",\"(g)\" ,\"(h)\",\n",
    "           \"(i)\",\"(j)\",\"(k)\", \"(l)\"]\n",
    "titles = [\"real data\"]\n",
    "nb_rows=2\n",
    "i = 0\n",
    "ax = plt.subplot(nb_rows,3,i*4 +1)\n",
    "sns.barplot(x = \"method\", y=\"ARI\", data = all_data.sort_values(by=\"order\"),\n",
    "           palette=clrs,\n",
    "           edgecolor='black',\n",
    "    linewidth=1.5)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(f\"{letters[i*4]} ARI {titles[i]}\")\n",
    "plt.xlabel(\"\")\n",
    "sns.despine()\n",
    "for j in range(7,13):\n",
    "    plt.text(j, 0.7, \"*\")\n",
    "\n",
    "ax = plt.subplot(nb_rows,3,i*4 +2)\n",
    "sns.barplot(x = \"method\", y=\"NMI\", data = all_data.sort_values(by=\"order\"),\n",
    "           palette=clrs,\n",
    "           edgecolor='black',\n",
    "    linewidth=1.5)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.xlabel(\"\")\n",
    "plt.title(f\"{letters[i*4 +1]} NMI {titles[i]}\")\n",
    "for j in range(7,13):\n",
    "    plt.text(j, 0.8, \"*\")\n",
    "\n",
    "ax = plt.subplot(nb_rows,3,i*4 +3)\n",
    "sns.barplot(x = \"method\", y=\"Silhouette\", data = all_data.sort_values(by=\"order\"),\n",
    "           palette=clrs,\n",
    "           edgecolor='black',\n",
    "    linewidth=1.5)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(f\"{letters[i*4 +2]} Silhouette {titles[i]}\")\n",
    "plt.xlabel(\"\")\n",
    "for j in range(7,13):\n",
    "    plt.text(j, 0.6, \"*\")\n",
    "sns.despine()\n",
    "\n",
    "## Nb predicted clusters\n",
    "ax = plt.subplot(nb_rows,3,i*4 +4)\n",
    "g= sns.barplot(x = \"method\", y=\"Calinski\", data = all_data.sort_values(by=\"order\"),\n",
    "           palette=clrs,\n",
    "           edgecolor='black',\n",
    "    linewidth=1.5)\n",
    "g.set(yscale=\"log\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.ylabel(\"log Calinski\")\n",
    "plt.title(f\"{letters[i*4 +3]}  Calinski {titles[i]}\")\n",
    "plt.xlabel(\"\")\n",
    "for j in range(7,13):\n",
    "    plt.text(j, 20000, \"*\")\n",
    "sns.despine()\n",
    "    \n",
    "    \n",
    "ax = plt.subplot(nb_rows, 3, 5)\n",
    "g = sns.barplot(x = \"method\", y=\"time\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "           linewidth=1.5\n",
    "           )\n",
    "g.set(yscale=\"log\")\n",
    "plt.axhline(y=1, c = \"black\")\n",
    "plt.ylabel(\"log seconds\")\n",
    "plt.xticks(rotation = 90)\n",
    "for j in range(7,13):\n",
    "    plt.text(j, 3000, \"*\")\n",
    "plt.title(f\"(e) Execution time\")\n",
    "sns.despine()\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "\n",
    "ax = plt.subplot(nb_rows, 3, 6)\n",
    "sns.barplot(x = \"method\", y=\"nb_pred_clust\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "           linewidth=1.5\n",
    "           )\n",
    "plt.axhline(y=1, c = \"black\")\n",
    "plt.ylabel(\"Nb predicted clusters\")\n",
    "plt.xticks(rotation = 90)\n",
    "for j in range(7,13):\n",
    "    plt.text(j, 4, \"*\")\n",
    "plt.title(f\"(f) Nb predicted clusters\")\n",
    "sns.despine()\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"../diagrams/real.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.groupby(\"method\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles = [\"(a)\", \"(b)\", \"(c)\", \"(d)\"]\n",
    "# plt.figure(figsize = (12, 12))\n",
    "# category = \"balanced_data\"\n",
    "# all_data = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_combined.pkl\")\n",
    "\n",
    "# for i, dropout in enumerate(sorted(all_data.dropout.unique())):\n",
    "#     ax = plt.subplot(4, 2, i+1)\n",
    "#     sns.barplot(x = \"nb_clust\", y=\"ARI\", \n",
    "#                 data = all_data[all_data[\"dropout\"] == dropout].sort_values(by=[\"nb_clust\", \"order\"]),\n",
    "#                 hue = \"method\",\n",
    "#                palette=clrs,\n",
    "#                edgecolor='black',\n",
    "#         linewidth=1.5)\n",
    "\n",
    "#     plt.title(f\"{titles[i]} Balanced data, dropout rate {dropout} %\")\n",
    "#     if i ==1:\n",
    "#         plt.legend(bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "# #         plt.legend(bbox_to_anchor=(0., 1.4), loc=2, borderaxespad=0., ncol=7)\n",
    "#     else: \n",
    "#         plt.legend([],[], frameon=False)\n",
    "\n",
    "#     plt.xlabel(\"\")\n",
    "#     sns.despine()\n",
    "    \n",
    "    \n",
    "# category = \"imbalanced_data\"\n",
    "# all_data = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_combined.pkl\")\n",
    "# titles = [\"(e)\", \"(f)\", \"(g)\", \"(g)\"]\n",
    "# for i, dropout in enumerate(sorted(all_data.dropout.unique())):\n",
    "#     ax = plt.subplot(4, 2, i+5)\n",
    "#     sns.barplot(x = \"nb_clust\", y=\"ARI\", \n",
    "#                 data = all_data[all_data[\"dropout\"] == dropout].sort_values(by=[\"nb_clust\", \"order\"]),\n",
    "#                 hue = \"method\",\n",
    "#                palette=clrs,\n",
    "#                edgecolor='black',\n",
    "#         linewidth=1.5)\n",
    "\n",
    "#     plt.title(f\"{titles[i]} Imbalanced data, dropout rate {dropout} %\")\n",
    "\n",
    "#     plt.legend([],[], frameon=False)\n",
    "#     if i in [2, 3]:\n",
    "#         plt.xlabel(\"Nb. of clusters\")\n",
    "#     else:\n",
    "#         plt.xlabel(\"\")\n",
    "#     sns.despine()\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f\"../diagrams/{category}_barplot_by_dropout.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles = [\"(a)\", \"(b)\", \"(c)\", \"(d)\"]\n",
    "# plt.figure(figsize = (12, 5))\n",
    "# for i, dropout in enumerate(sorted(all_data.dropout.unique())):\n",
    "#     ax = plt.subplot(2, 2, i+1)\n",
    "#     sns.barplot(x = \"nb_clust\", y=\"ARI\", \n",
    "#                 data = all_data[all_data[\"dropout\"] == dropout].sort_values(by=[\"nb_clust\", \"order\"]),\n",
    "#                 hue = \"method\",\n",
    "#                palette=clrs,\n",
    "#                edgecolor='black',\n",
    "#         linewidth=1.5)\n",
    "\n",
    "#     plt.title(f\"{titles[i]} dropout rate {dropout} %\")\n",
    "#     if i ==1:\n",
    "#         plt.legend(bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "#     else: \n",
    "#         plt.legend([],[], frameon=False)\n",
    "#     if i in [2, 3]:\n",
    "#         plt.xlabel(\"Nb. of clusters\")\n",
    "#     else:\n",
    "#         plt.xlabel(\"\")\n",
    "#     sns.despine()\n",
    "# # plt.tight_layout()\n",
    "# plt.savefig(f\"../diagrams/{category}_barplot_by_dropout.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 12))\n",
    "letters = [\"(a)\", \"(b)\", \"(c)\", \"(d)\",\n",
    "           \"(e)\", \"(f)\",\"(g)\" ,\"(h)\",\n",
    "           \"(i)\",\"(j)\",\"(k)\", \"(l)\"]\n",
    "titles = [\"balanced data\", \"imbalanced data\", \"real data\"]\n",
    "for i, category in enumerate ([\"balanced_data\", \"imbalanced_data\", \"real_data\"] ):\n",
    "    all_data = pd.read_pickle(f\"../output/pickle_results/{category}/{category}_combined.pkl\")\n",
    "    \n",
    "    ax = plt.subplot(3,4,i*4 +1)\n",
    "    sns.barplot(x = \"method\", y=\"ARI\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=1.5)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"{letters[i*4]} ARI {titles[i]}\")\n",
    "    plt.xlabel(\"\")\n",
    "    sns.despine()\n",
    "\n",
    "    ax = plt.subplot(3,4,i*4 +2)\n",
    "    sns.barplot(x = \"method\", y=\"NMI\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=1.5)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.title(f\"{letters[i*4 +1]} NMI {titles[i]}\")\n",
    "\n",
    "    ax = plt.subplot(3,4,i*4 +3)\n",
    "    sns.barplot(x = \"method\", y=\"Silhouette\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=1.5)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"{letters[i*4 +2]} Silhouette {titles[i]}\")\n",
    "    plt.xlabel(\"\")\n",
    "    sns.despine()\n",
    "\n",
    "    ax = plt.subplot(3,4,i*4 +4)\n",
    "    g= sns.barplot(x = \"method\", y=\"Calinski\", data = all_data.sort_values(by=\"order\"),\n",
    "               palette=clrs,\n",
    "               edgecolor='black',\n",
    "        linewidth=1.5)\n",
    "    g.set(yscale=\"log\")\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(f\"{letters[i*4 +3]}  Calinski {titles[i]}\")\n",
    "    plt.xlabel(\"\")\n",
    "    sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"../diagrams/all_barplot.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
