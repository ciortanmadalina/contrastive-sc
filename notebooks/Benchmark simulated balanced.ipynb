{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original implementation of Contrastive-sc method\n",
    "(https://github.com/ciortanmadalina/contrastive-sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import st_loss\n",
    "\n",
    "import h5py\n",
    "import scipy as sp\n",
    "import scanpy.api as sc\n",
    "from collections import Counter\n",
    "import utils\n",
    "import loop\n",
    "import pickle\n",
    "import glob2\n",
    "import os\n",
    "plt.ion()\n",
    "plt.show()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"balanced_data\"\n",
    "path = \"../\"\n",
    "args = {\n",
    "    \"dims\": [499, 256, 64, 32],\n",
    "    \"highly_genes\": 500,\n",
    "    'alpha': 0.001,\n",
    "    'gamma': 0.001,\n",
    "    'learning_rate': 0.0001,\n",
    "    'update_epoch': 10,\n",
    "    't_alpha': 1,\n",
    "    'error': 0.001\n",
    "}\n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n",
    "args = objectview(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{path}output/{category}\", exist_ok = True)\n",
    "os.makedirs(f\"{path}output/pickle_results/{category}\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob2.glob(f'../R/simulated_data/{category}/*.h5')\n",
    "files = [f[len(f\"{path}R/simulated_data/{category}/\"):-3] for f in files]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for run in range(3):\n",
    "    df = pd.DataFrame()\n",
    "    print(df.shape)\n",
    "    for dataset in files:\n",
    "        print(f\">>>>> Data {dataset}\")\n",
    "\n",
    "        data_mat = h5py.File(f\"{path}R/simulated_data/{category}/{dataset}.h5\", \"r\")\n",
    "        X = np.array(data_mat['X'])\n",
    "        Y = np.array(data_mat['Y'])\n",
    "        print(f\"Dropout level {data_mat['dropout'][0]}\")\n",
    "        dp = data_mat['dropout'][0]\n",
    "        print(np.where(X ==0)[0].shape[0]/(X.shape[0]*X.shape[1]))\n",
    "\n",
    "\n",
    "        X = np.ceil(X).astype(np.int)\n",
    "        count_X = X\n",
    "        print(X.shape, count_X.shape)\n",
    "        orig_X = X.copy()\n",
    "        adata = sc.AnnData(X)\n",
    "        adata.obs['Group'] = Y\n",
    "        adata = utils.normalize(adata,\n",
    "                          copy=True,\n",
    "                          highly_genes=args.highly_genes,\n",
    "                          size_factors=True,\n",
    "                          normalize_input=True,\n",
    "                          logtrans_input=True)\n",
    "        X = adata.X.astype(np.float32)\n",
    "        Y = np.array(adata.obs[\"Group\"])\n",
    "        print(X.shape, count_X.shape)\n",
    "\n",
    "        high_variable = np.array(adata.var.highly_variable.index, dtype=np.int)\n",
    "        count_X = count_X[:, high_variable]\n",
    "        cluster_number = int(max(Y) - min(Y) + 1)\n",
    "        zeros = np.min(X, axis = 0)\n",
    "        pxt = PCA(2).fit_transform(X)\n",
    "        dresults = {\n",
    "            \"dataset\": dataset,\n",
    "            \"dropout\": data_mat['dropout'][0],\n",
    "            \"nclust\": cluster_number,\n",
    "            \"original\": utils.evaluate(X, Y, cluster_number)[1],\n",
    "            \"pca\": utils.evaluate(pxt, Y, cluster_number)[1]\n",
    "        }\n",
    "        # 3 models\n",
    "        st_results = []\n",
    "        predictions1 = []\n",
    "        predictions2 = []\n",
    "        nm = \"500epoch\"\n",
    "        f = []\n",
    "        for i in range(3):\n",
    "            r1 = loop.self_train_clustering(X,\n",
    "                   Y,\n",
    "                   cluster_number,\n",
    "                   args,\n",
    "                   augm_zeros=None,\n",
    "                   nb_zeros= \"random\", \n",
    "                   random=False,\n",
    "                   perc=0.1,\n",
    "                   augm_value=0,\n",
    "                   model_name = \"STClustering\",\n",
    "                   epochs = 500)\n",
    "            f.append(r1['features'])\n",
    "            st_results.append(r1)\n",
    "            predictions1.append(r1['pred_kmeans_representation'])\n",
    "            predictions2.append(r1['pred'])\n",
    "            dresults[f\"method1_{i}\"] = r1[\"aris_kmeans_representation\"][-1]\n",
    "            dresults[f\"method2_{i}\"] = r1[\"aris\"][-1]\n",
    "\n",
    "        ft = np.hstack(f)\n",
    "        kmeans = KMeans(n_clusters=cluster_number, init=\"k-means++\", random_state=0)\n",
    "        pred = kmeans.fit_predict(ft)\n",
    "        predictions1.append(pred)\n",
    "        predictions2.append(pred)\n",
    "        dresults[f\"method3\"] = adjusted_rand_score(Y, pred)\n",
    "\n",
    "        df = df.append(dresults, ignore_index=True)\n",
    "        print(dresults)\n",
    "\n",
    "        all_res = dresults.copy()\n",
    "        all_res[\"st\"] = st_results\n",
    "\n",
    "        with open(f\"{path}output/{category}/results_{dataset}_{run}.pickle\", 'wb') as handle:\n",
    "            pickle.dump(dresults, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open(f\"{path}output/{category}/detailed_results_{dataset}_{run}.pickle\", 'wb') as handle:\n",
    "            pickle.dump(all_res, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        df.to_pickle(f\"{path}output/pickle_results/{category}/{category}_run_{run}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 0\n",
    "df = pd.read_pickle(f\"{path}output/pickle_results/{category}/{category}_run_{run}.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
